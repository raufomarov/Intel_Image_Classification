{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, array_to_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Download ResNet50 weights\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /kaggle/working/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "\n",
    "# Download Inception_v3 weights\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /kaggle/working/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "\n",
    "# Download VGG16 weights\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /kaggle/working/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train and validation directories\n",
    "import os\n",
    "\n",
    "train_dir = os.path.join('../input/intel-image-classification/seg_train/seg_train')\n",
    "validation_dir = os.path.join('../input/intel-image-classification/seg_test/seg_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Directory with our training mountain pictures\n",
    "train_mountain_dir = os.path.join('../input/intel-image-classification/seg_train/seg_train/mountain')\n",
    "\n",
    "# Directory with our training forest pictures\n",
    "train_forest_dir = os.path.join('../input/intel-image-classification/seg_train/seg_train/forest')\n",
    "\n",
    "# Directory with our validation mountain pictures\n",
    "validation_mountain_dir = os.path.join('../input/intel-image-classification/seg_test/seg_test/mountain')\n",
    "\n",
    "# Directory with our validation forest pictures\n",
    "validation_forest_dir = os.path.join('../input/intel-image-classification/seg_test/seg_test/forest') \n",
    "\n",
    "train_mountain_fnames = glob.glob(train_mountain_dir+\"/*\")\n",
    "train_forest_fnames = glob.glob(train_forest_dir+\"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5\n",
    "\n",
    "sample_mountain_fnames = np.random.choice(train_mountain_fnames, size=sample_size, replace=False)\n",
    "sample_forest_fnames = np.random.choice(train_forest_fnames, size=sample_size, replace=False)\n",
    "\n",
    "sample_mountain_images = [img_to_array(load_img(fname, target_size=(150, 150), interpolation='bilinear')) for fname in sample_mountain_fnames]\n",
    "sample_forest_images = [img_to_array(load_img(fname, target_size=(150, 150), interpolation='bilinear')) for fname in sample_forest_fnames]\n",
    "\n",
    "sample_mountain_images = np.array(sample_mountain_images).astype('float32')/255.\n",
    "sample_forest_images = np.array(sample_forest_images).astype('float32')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, sample_size, figsize=(sample_size * 5, 15))\n",
    "for i in range(sample_size):\n",
    "  ax[i].imshow(sample_mountain_images[i])\n",
    " \n",
    "\n",
    "fig, ax = plt.subplots(1, sample_size, figsize=(sample_size * 5, 15))\n",
    "for i in range(sample_size):\n",
    "  ax[i].imshow(sample_forest_images[i])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image augmentation techniques and data generators\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'categorical', \n",
    "                                                    target_size = (150, 150))    \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                              batch_size=32,\n",
    "                                                              class_mode='categorical',\n",
    "                                                              target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models\n",
    "vgg16_weights_path = '/kaggle/working/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "inception_v3_weights_path = '/kaggle/working/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "resnet50_weights_path = '/kaggle/working/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "vgg16_model = VGG16(input_shape = (150, 150, 3),\n",
    "                    include_top = False,\n",
    "                    weights = None)\n",
    "\n",
    "inception_v3_model = InceptionV3(input_shape = (150, 150, 3),\n",
    "                                 include_top = False,\n",
    "                                 weights = None)\n",
    "\n",
    "resnet50_model = ResNet50(input_shape = (150, 150, 3),\n",
    "                          include_top = False,\n",
    "                          weights = None)\n",
    "\n",
    "vgg16_model.load_weights(vgg16_weights_path)\n",
    "inception_v3_model.load_weights(inception_v3_weights_path)\n",
    "resnet50_model.load_weights(resnet50_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the model architecture: vgg16\n",
    "plot_model(vgg16_model, to_file='/tmp/vgg16_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the model architecture: inception_v3\n",
    "plot_model(inception_v3_model, to_file='/tmp/inception_v3_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the model architecture: resnet50\n",
    "plot_model(resnet50_model, to_file='/tmp/resnet50_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe vgg16\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe inception_v3\n",
    "inception_v3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe resnet50\n",
    "resnet50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers\n",
    "for layer in vgg16_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "for layer in inception_v3_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "for layer in resnet50_model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compile_model(pre_trained_model):\n",
    "  last_layer = pre_trained_model.layers[-1]\n",
    "  last_output = last_layer.output\n",
    "    \n",
    "    \n",
    "  x = layers.Flatten()(last_output)\n",
    "  x = layers.Dense(1024, activation='relu')(x)\n",
    "  x = layers.Dropout(0.2)(x)                  \n",
    "  x = layers.Dense(1, activation='softmax')(x)           \n",
    "\n",
    "  model = Model(pre_trained_model.input, x) \n",
    "  model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "                loss = 'categorical_crossentropy', \n",
    "                metrics = ['accuracy'])\n",
    "  return model\n",
    "\n",
    "transfered_vgg16_model = compile_model(vgg16_model)\n",
    "transfered_inception_v3_model = compile_model(inception_v3_model)\n",
    "transfered_resnet50_model= compile_model(resnet50_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe transfered_vgg16_model\n",
    "transfered_vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfered_inception_v3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe transfered_resnet50_model\n",
    "transfered_resnet50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "     history_vgg16 = transfered_vgg16_model.fit(\n",
    "                            train_generator,\n",
    "                            validation_data = validation_generator,\n",
    "                            epochs = 20,\n",
    "                            validation_steps = 50,\n",
    "                            use_multiprocessing=True,\n",
    "                            verbose = 2)\n",
    "        \n",
    "except InvalidArgumentError:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "      history_resnet50 = transfered_resnet50_model.fit(\n",
    "                            train_generator,\n",
    "                            validation_data = validation_generator,\n",
    "                            epochs = 20,\n",
    "                            validation_steps = 50,\n",
    "                            verbose = 2)\n",
    "        \n",
    "except InvalidArgumentError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "      history_inception_v3 = transfered_inception_v3_model.fit(\n",
    "                            train_generator,\n",
    "                            validation_data = validation_generator,\n",
    "                            epochs = 20,\n",
    "                            validation_steps = 50,\n",
    "                            use_multiprocessing=True,\n",
    "                             verbose = 2)\n",
    "        \n",
    "except InvalidArgumentError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(history, model_name):\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "  plt.title(f'Training and validation accuracy [{model_name}]')\n",
    "  plt.legend(loc=0)\n",
    "  plt.figure()\n",
    "  plt.show()\n",
    "\n",
    "plot_acc(history_vgg16, 'VGG16')\n",
    "plot_acc(history_inception_v3, 'Inception_v3')\n",
    "plot_acc(history_resnet50, 'ResNet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5\n",
    "model = transfered_vgg16_model \n",
    "\n",
    "sample_mountain_fnames = np.random.choice(train_mountain_fnames, size=sample_size, replace=False)\n",
    "sample_forest_fnames = np.random.choice(train_forest_fnames, size=sample_size, replace=False)\n",
    "\n",
    "sample_mountain_images = [img_to_array(load_img(fname, target_size=(150, 150), interpolation='bilinear')) for fname in sample_mountain_fnames]\n",
    "sample_forest_images = [img_to_array(load_img(fname, target_size=(150, 150), interpolation='bilinear')) for fname in sample_forest_fnames]\n",
    "\n",
    "sample_mountain_images = np.array(sample_mountain_images).astype('float32')/255.\n",
    "sample_forest_images = np.array(sample_forest_images).astype('float32')/255.\n",
    "\n",
    "\n",
    "\n",
    "mountain_pred = model.predict(sample_mountain_images).flatten()\n",
    "forest_pred = model.predict(sample_forest_images).flatten()\n",
    "\n",
    "fig, ax = plt.subplots(1, sample_size, figsize=(sample_size * 5, 15))\n",
    "for i in range(sample_size):\n",
    "  ax[i].imshow(sample_mountain_images[i])\n",
    "  ax[i].set_title(f\"Mountain: {mountain_pred[i]:.2f}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, sample_size, figsize=(sample_size * 5, 15))\n",
    "for i in range(sample_size):\n",
    "  ax[i].imshow(sample_forest_images[i])\n",
    "  ax[i].set_title(f\"Forest: {forest_pred[i]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
